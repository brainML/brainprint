{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy.io as sio\n",
    "from scipy.stats.stats import pearsonr   \n",
    "import scipy.stats as ss\n",
    "import scipy.signal as ssg\n",
    "from scipy.io import savemat\n",
    "import time\n",
    "import h5py\n",
    "import mne\n",
    "import timeit\n",
    "import random\n",
    "import glob  \n",
    "import re\n",
    "\n",
    "def spatial_cov(data):\n",
    "    #input[ch time nstimuli]\n",
    "    return(np.cov(data.reshape([data.shape[0],-1])))\n",
    "\n",
    "def spatial_corr(data):\n",
    "    #input[ch time nstimuli]\n",
    "    return(np.corrcoef(data.reshape([data.shape[0],-1])))\n",
    "\n",
    "\n",
    "def temporal_cov(data):\n",
    "    #input[ch time nstimuli]\n",
    "    data=np.swapaxes(data,1,0)\n",
    "    return(np.cov(data.reshape([data.shape[0],-1])))\n",
    "\n",
    "def temporal_corr(data):\n",
    "    #input[ch time nstimuli]\n",
    "    data=np.swapaxes(data,1,0)\n",
    "    return(np.corrcoef(data.reshape([data.shape[0],-1])))\n",
    "\n",
    "\n",
    "def compress_dim_by_n_nosti(data,dim,n):\n",
    "    #assume data is of [nch ntime ]\n",
    "    \n",
    "    data_output=np.zeros([int(data.shape[0]/n),data.shape[1]])\n",
    "    for i in range(data_output.shape[0]):\n",
    "        data_output[i]=np.mean(data[i*n:(i+1)*n],axis=0)\n",
    "   \n",
    "    return(data_output)\n",
    "\n",
    "\n",
    "def compress_dim_by_n(data,dim,n):\n",
    "    #assume data is of [ntime nch nstimuli]\n",
    "    if dim==0:\n",
    "        data_output=np.zeros([int(data.shape[0]/n),data.shape[1],data.shape[2]])\n",
    "        for i in range(data_output.shape[0]):\n",
    "            data_output[i]=np.mean(data[i*n:(i+1)*n],axis=0)\n",
    "    elif dim ==1:\n",
    "        data_output=np.zeros([data.shape[0],int(data.shape[1]/n),data.shape[2]])\n",
    "        for i in range(data_output.shape[1]):\n",
    "            data_output[:,i,:]=np.mean(data[:,i*n:(i+1)*n,:],axis=1)\n",
    "    return(data_output)\n",
    "\n",
    "\n",
    "def featurize_data(input_data, n_train, sampling_type):\n",
    "    if not 'noparse' in sampling_type:\n",
    "        if n_train>input_data.shape[2]:\n",
    "            n_train=input_data.shape[2]\n",
    "    ### in the [102, 100] case\n",
    "    if sampling_type == 'spatial_cov':\n",
    "        inds=np.random.choice(range(input_data.shape[2]),n_train,replace=False)\n",
    "        features = spatial_cov(input_data[:,:,inds])\n",
    "        features=np.array(features)\n",
    "    elif sampling_type == 'spatial_corr':\n",
    "        inds=np.random.choice(range(input_data.shape[2]),n_train,replace=False)\n",
    "        features = spatial_corr(input_data[:,:,inds])\n",
    "        features=np.array(features)\n",
    "    elif sampling_type == 'temporal_cov':\n",
    "        inds=np.random.choice(range(input_data.shape[2]),n_train,replace=False)\n",
    "        features = temporal_cov(input_data[:,:,inds])\n",
    "        features=np.array(features)    \n",
    "    elif sampling_type == 'temporal_corr':\n",
    "        inds=np.random.choice(range(input_data.shape[2]),n_train,replace=False)\n",
    "        features = temporal_corr(input_data[:,:,inds])\n",
    "        features=np.array(features)\n",
    "    elif sampling_type == 'freq_spatial': \n",
    "        #[nch  nfreq]\n",
    "        nt = input_data.shape[1]\n",
    "        inds=np.random.choice(range(input_data.shape[2]),n_train,replace=False)\n",
    "        f,t,Sxx =ssg.spectrogram(np.swapaxes(input_data[:,:,inds],1,2), fs=200,nfft=nt,nperseg=nt)\n",
    "        features= np.squeeze(Sxx.mean(axis=1))\n",
    "        features=np.array(features)          \n",
    "    elif sampling_type == 'freq_temporal':\n",
    "        nt = input_data.shape[1]\n",
    "        inds=np.random.choice(range(input_data.shape[2]),n_train,replace=False)\n",
    "        f,t,Sxx =ssg.spectrogram(np.swapaxes(input_data[:,:,inds],1,2), fs=200,noverlap=nt-1,nperseg=nt)\n",
    "        Sxx=np.swapaxes(Sxx,-1,-2)\n",
    "        features= np.squeeze(Sxx.mean(axis=1))\n",
    "        features=np.array(features)\n",
    "    else:\n",
    "        print('wrong sampling_type!')\n",
    "    return(features)\n",
    "\n",
    "def compare_features(features1, features2, metric='corr',individual = False):\n",
    "    # compare features1 to features2 (order matters!)\n",
    "    y_true = np.arange(len(features1))\n",
    "    if metric=='corr':\n",
    "        dists = np.corrcoef(features1.reshape(features1.shape[0],-1),features2.reshape(features2.shape[0],-1))[:len(features1),len(features1):]\n",
    "    else:\n",
    "        print('unrecognized metric!')\n",
    "    y_pred=np.argmax(dists,axis=1)\n",
    "    if individual:\n",
    "        return(y_pred==y_true)\n",
    "    else:\n",
    "        return(np.mean(y_pred==y_true))\n",
    "\n",
    "\n",
    "def get_acc_results(data, nrep=100,individual = False):\n",
    "    # return [n_trainsizes, nsession^2, number of nrep]\n",
    "    accs = []\n",
    "    for kk in range(int(len(data[0][0])/nrep)): # train size loop\n",
    "        accs_tmp=[]\n",
    "        for i in range(len(data)):\n",
    "            for j in range(len(data)):\n",
    "                accs_tmp_tmp=[]                \n",
    "                for k in range(nrep):\n",
    "                    features1=data[i,:,k+kk*nrep]\n",
    "                    features2=data[j,:,k+kk*nrep]\n",
    "                    accs_tmp_tmp.append(compare_features(features1, features2,'corr',individual))\n",
    "                accs_tmp.append(accs_tmp_tmp) \n",
    "        accs.append(accs_tmp)\n",
    "    return(np.array(accs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FST data featurizationÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_featurization(data,savename,train_size, onset = 'after',within=False):\n",
    "    if onset == 'after':\n",
    "        data=data[:,:306,201:]\n",
    "        data=np.swapaxes(data,0,1)\n",
    "        data=np.swapaxes(data,1,2)\n",
    "        data = compress_dim_by_n(data,0,3)\n",
    "        data = ssg.decimate(data,5,axis=1)\n",
    "    elif onset == 'before':\n",
    "        data=data[:,:306,:200]\n",
    "        data=np.swapaxes(data,0,1)\n",
    "        data=np.swapaxes(data,1,2)\n",
    "        data = compress_dim_by_n(data,0,3)\n",
    "        data = ssg.decimate(data,5,axis=1)   \n",
    "    if within: \n",
    "        if data.shape[2]/2<train_size[0]:\n",
    "            train_size=int(data.shape[2]/2)\n",
    "            print('n trials too few!')\n",
    "        datashape = data.shape\n",
    "        feature1 = []\n",
    "        feature2 = []\n",
    "        feature3 = []\n",
    "        feature1_2 = []\n",
    "        feature2_2 = []\n",
    "        feature3_2 = []\n",
    "        for n_train in train_size:\n",
    "            for kkk in range(100):\n",
    "                ind_data1 = np.random.choice(range(data.shape[2]), n_train,replace=False)\n",
    "                data1 = data[:,:,ind_data1]\n",
    "                ind_data2 = np.random.choice([x for x in list(range(data.shape[2])) if x not in ind_data1], n_train,replace=False)\n",
    "                data2 = data[:,:,ind_data2]\n",
    "                ntimes = data1.shape[1]\n",
    "                data1=np.reshape(data1,[102,-1],order='F')\n",
    "                data1=ss.zscore(data1,axis=1)\n",
    "                data1=np.reshape(data1,[102,ntimes,-1],order='F')\n",
    "                ntimes = data2.shape[1]\n",
    "                data2=np.reshape(data2,[102,-1],order='F')\n",
    "                data2=ss.zscore(data2,axis=1)\n",
    "                data2=np.reshape(data2,[102,ntimes,-1],order='F')\n",
    "\n",
    "                sampling_type='spatial_corr'\n",
    "                features = featurize_data(data1, n_train, sampling_type)\n",
    "                feature1.append(features)\n",
    "\n",
    "                sampling_type='temporal_corr'\n",
    "                features = featurize_data(data1, n_train, sampling_type)\n",
    "                feature2.append(features)\n",
    "\n",
    "                sampling_type='freq_spatial'\n",
    "                features = featurize_data(data1, n_train, sampling_type)\n",
    "                features=np.mean(features,axis=0)\n",
    "                feature3.append(features)\n",
    "\n",
    "\n",
    "                sampling_type='spatial_corr'\n",
    "                features = featurize_data(data2, n_train, sampling_type)\n",
    "                feature1_2.append(features)\n",
    "\n",
    "                sampling_type='temporal_corr'\n",
    "                features = featurize_data(data2, n_train, sampling_type)\n",
    "                feature2_2.append(features)\n",
    "\n",
    "\n",
    "                sampling_type='freq_spatial'\n",
    "                features = featurize_data(data2, n_train, sampling_type)\n",
    "                features=np.mean(features,axis=0)\n",
    "                feature3_2.append(features)\n",
    "        sio.savemat(savename,mdict={'feature1':feature1,'feature2':feature2,'feature3':feature3,'feature1_2':feature1_2 ,'feature2_2':feature2_2,\\\n",
    "                           'feature3_2':feature3_2,'datashape':datashape})\n",
    "    else:\n",
    "    #featurization step\n",
    "        data=np.reshape(data,[102,-1],order='F')\n",
    "        data=ss.zscore(data,axis=1)\n",
    "        data=np.reshape(data,[102,100,-1],order='F')\n",
    "        feature1 = []\n",
    "        feature2 = []\n",
    "        feature3 = []\n",
    "        for n_train in train_size:\n",
    "            for kk in range(100):\n",
    "                #spatial\n",
    "                sampling_type='spatial_corr'\n",
    "                features = featurize_data(data, n_train, sampling_type)\n",
    "                feature1.append(features)\n",
    "                #temporal\n",
    "                sampling_type='temporal_corr'\n",
    "                features = featurize_data(data, n_train, sampling_type)\n",
    "                feature2.append(features)\n",
    "                #freq\n",
    "                sampling_type='freq_spatial'\n",
    "                features = featurize_data(data, n_train, sampling_type)\n",
    "                features=np.mean(features,axis=0)\n",
    "                feature3.append(features)\n",
    "        datashape = data.shape\n",
    "        sio.savemat(savename, {'feature1':feature1,'feature2':feature2,'feature3':feature3,'datashape':datashape})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating FST features on datasets of different level of preprocessing\n",
    "root_dir = \"path_to_data\";\n",
    "start = time.time()\n",
    "subj_names = ['AT','DR','JG','JK']\n",
    "for subj in subj_names:\n",
    "    for session in [1,2,3,4]:\n",
    "        names = glob.glob(root_dir+subj+'/session'+str(session)+'/fst_b*.fif')\n",
    "\n",
    "        data=np.empty(shape=[0, 306, 701])\n",
    "        for fname in names:\n",
    "            data = np.row_stack((data,sio.loadmat(fname+'data.mat')['data']))\n",
    "        savename=fname[:-6]+'feature_raw.mat'\n",
    "        train_size=[300]\n",
    "        full_featurization(data,savename,train_size,'after')\n",
    "        print(savename)\n",
    "\n",
    "        data=np.empty(shape=[0, 306, 701])\n",
    "        for fname in names:\n",
    "            data = np.row_stack((data,sio.loadmat(fname+'data_sst_empty_filter_ecg_eog.mat')['data']))\n",
    "        savename=fname[:-6]+'feature_sst_empty_filter_ecg_eog.mat'\n",
    "        train_size=[1,5,10,25,50,100,200,300]\n",
    "        full_featurization(data,savename,train_size,'after')     \n",
    "        print(savename)\n",
    "        \n",
    "        savename=fname[:-6]+'feature_sst_empty_filter_ecg_eog.mat'\n",
    "        train_size=[300]\n",
    "        full_featurization(data,savename,train_size,'after',True)     \n",
    "        print(savename)\n",
    "        \n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HCP data featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd 'path_to_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find common indices between resting and working memory datasets\n",
    "import re\n",
    "import glob, os\n",
    "\n",
    "rmeg = glob.glob(\"./resting_state/*\")\n",
    "rmeg=[rmeg[i] for  i in range(len(rmeg)) if '.mat' not in rmeg[i]]\n",
    "rmeg = list([int(re.findall(\"(\\d{6})\", rmeg[i])[0]) for i in range(len(rmeg))])\n",
    "\n",
    "wmeg = glob.glob(\"./working_memory/*\")\n",
    "wmeg=[wmeg[i] for  i in range(len(wmeg)) if '.mat' not in wmeg[i]]\n",
    "wmeg = list([int(re.findall(\"(\\d{6})\", wmeg[i])[0]) for i in range(len(wmeg))])\n",
    "\n",
    "print(len(list(set(rmeg) & set(wmeg)) ))\n",
    "common_ids = np.sort(list(set(rmeg) & set(wmeg)))\n",
    "common_ch=np.squeeze(sio.loadmat('./ch_inds.mat') ['common_ch'] ) \n",
    "common_ch=[common_ch[i].replace(\" \", \"\") for i in range(len(common_ch))]\n",
    "print(len(common_ch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#within-session featurization. Splitting the dataset for each individual into shuffled, non-overlapping trials for training and testing.\n",
    "\n",
    "def HPC_featurization_within(postfix,train_size,t_begins,t_ends,n_train_rep=25,session_types=[0,1]):\n",
    "    start = time.time()\n",
    "    n_common = len(common_ids)\n",
    "    for session_type in session_types:\n",
    "\n",
    "        for i in range(len(common_ids)):\n",
    "            if session_type==0:\n",
    "                ind_names = glob.glob('./resting_state/'+str(common_ids[i])+'/MEG/Restin/rmegpreproc/*preproc.mat')\n",
    "            else:\n",
    "                ind_names = glob.glob('./working_memory/'+str(common_ids[i])+'/MEG/Wrkmem/tmegpreproc/*preproc_TIM.mat')\n",
    "            ind_sessions = list([int(re.findall(\"(\\d{1})-\", ind_names[i])[0]) for i in range(len(ind_names))])\n",
    "            data_tmp=[]\n",
    "            for loadname in ind_names:\n",
    "                mat = sio.loadmat(loadname)\n",
    "                data=mat['data']\n",
    "                label_tmp=data[0][0]['label']\n",
    "                label_tmp=[label_tmp[ii][0][0] for ii in range(len(label_tmp))]\n",
    "                tmp_mask=np.zeros(len(label_tmp),dtype=bool)\n",
    "                for jj in range(len(label_tmp)):\n",
    "                    if label_tmp[jj] in common_ch:\n",
    "                        tmp_mask[jj]=True\n",
    "                #featurization\n",
    "                trials = data[0][0]['trial'][0]\n",
    "                #data_tmp=ssg.decimate(trials[0][:,10:1010],10,axis=1)\n",
    "\n",
    "                for iii in range(trials.shape[0]):\n",
    "                    data_tmp.append(ssg.decimate(trials[iii][tmp_mask,t_begins[session_type]:t_ends[session_type]],5,axis=1))\n",
    "            data=np.swapaxes(np.swapaxes(np.array(data_tmp),0,1),1,2)\n",
    "            if data.shape[2]/2<train_size[0]:\n",
    "                train_size=[int(data.shape[2]/2)]\n",
    "                print('n trials too few!')\n",
    "            datashape = data.shape\n",
    "            feature1 = []\n",
    "            feature2 = []\n",
    "            feature3 = []\n",
    "            feature1_2 = []\n",
    "            feature2_2 = []\n",
    "            feature3_2 = []\n",
    "            for n_train in train_size:\n",
    "                for kkk in range(n_train_rep):\n",
    "                    ind_data1 = np.random.choice(range(data.shape[2]), n_train,replace=False)\n",
    "                    data1 = data[:,:,ind_data1]\n",
    "                    ind_data2 = np.random.choice([x for x in list(range(data.shape[2])) if x not in ind_data1], n_train,replace=False)\n",
    "                    data2 = data[:,:,ind_data2]\n",
    "                    ntimes = data1.shape[1]\n",
    "                    nch= data1.shape[0]\n",
    "                    data1=np.reshape(data1,[nch,-1],order='F')\n",
    "                    data1=ss.zscore(data1,axis=1)\n",
    "                    data1=np.reshape(data1,[nch,ntimes,-1],order='F')\n",
    "                    ntimes = data2.shape[1]\n",
    "                    data2=np.reshape(data2,[nch,-1],order='F')\n",
    "                    data2=ss.zscore(data2,axis=1)\n",
    "                    data2=np.reshape(data2,[nch,ntimes,-1],order='F')\n",
    "                    #spatial\n",
    "                    sampling_type='spatial_corr'\n",
    "                    features = featurize_data(data1, n_train, sampling_type)\n",
    "                    feature1.append(features)\n",
    "                    #freq spatial\n",
    "\n",
    "                     #temporal\n",
    "                    sampling_type='temporal_corr'\n",
    "                    features = featurize_data(data1, n_train, sampling_type)\n",
    "                    feature2.append(features)\n",
    "\n",
    "\n",
    "                    sampling_type='freq_spatial'\n",
    "                    features = featurize_data(data1, n_train, sampling_type)\n",
    "                    features=np.mean(features,axis=0)\n",
    "                    feature3.append(features)\n",
    "\n",
    "\n",
    "                    sampling_type='spatial_corr'\n",
    "                    features = featurize_data(data2, n_train, sampling_type)\n",
    "                    feature1_2.append(features)\n",
    "                    #freq spatial\n",
    "\n",
    "                     #temporal\n",
    "                    sampling_type='temporal_corr'\n",
    "                    features = featurize_data(data2, n_train, sampling_type)\n",
    "                    feature2_2.append(features)\n",
    "\n",
    "\n",
    "                    sampling_type='freq_spatial'\n",
    "                    features = featurize_data(data2, n_train, sampling_type)\n",
    "                    features=np.mean(features,axis=0)\n",
    "                    feature3_2.append(features)\n",
    "            if session_type==0:\n",
    "                sio.savemat('./resting_state/'+str(common_ids[i])+'/MEG/Restin/rmegpreproc/'+str(common_ids[i])+'_feature_'+postfix+'.mat',mdict={'feature1':feature1,'feature2':feature2,'feature3':feature3,'feature1_2':feature1_2 ,'feature2_2':feature2_2,'feature3_2':feature3_2,'datashape':datashape})\n",
    "            else:\n",
    "                sio.savemat('./working_memory/'+str(common_ids[i])+'/MEG/Wrkmem/tmegpreproc/'+str(common_ids[i])+'_TIM_feature_'+postfix+'.mat',mdict={'feature1':feature1,'feature2':feature2,'feature3':feature3,'feature1_2':feature1_2 ,'feature2_2':feature2_2,'feature3_2':feature3_2,'datashape':datashape})            \n",
    "            print(str(common_ids[i]))\n",
    "\n",
    "    end = time.time()\n",
    "    print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating features for the resting-state and working memory (task) datasets for within-session comparison\n",
    "postfixs=['within_r','within_t' ]\n",
    "train_size=[200]\n",
    "t_begins=[0,763] \n",
    "t_ends=[1018,763+1018]\n",
    "n_train_rep=100\n",
    "for s in range(len(2)):\n",
    "    session_types=[s]\n",
    "    postfix = postfixs[s]\n",
    "    HPC_featurization_within(postfix,train_size,t_begins,t_ends,n_train_rep,session_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEG-EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG = []\n",
    "subjs = [1,2,3,4,5,6,7,8,10,11,12,13,14,16,18]\n",
    "for i in subjs:\n",
    "    data = sio.loadmat('../EEG_no_aspect/Subj'+str(i)+'_EEG_1_110Hz_notch_ica_PPO10POO10_swapped_MEEG_match_ave_alpha15.0_no_aspect.mat')\n",
    "    EEG.append(data['ave_data'])\n",
    "    print(data['ave_data'].shape)\n",
    "\n",
    "MEG = []\n",
    "subjs = [1,2,3,4,5,6,7,8,10,11,12,13,14,16,18]\n",
    "for i in subjs:\n",
    "    data = sio.loadmat('../MEG_no_aspect/Subj'+str(i)+'_1_110Hz_notch_ica_MEEG_match_ave_alpha15.0_no_aspect.mat')\n",
    "    MEG.append(data['ave_data'])\n",
    "    print(data['ave_data'].shape)\n",
    "\n",
    "meg_tp = []\n",
    "meg_fq = []\n",
    "n_train_rep=100\n",
    "ntrain = 200\n",
    "for i in range(len(MEG)):\n",
    "    data = MEG[i].swapaxes(0,2).swapaxes(0,1)\n",
    "    tmp_tp = []\n",
    "    tmp_fq = []\n",
    "    for j in range(n_train_rep):\n",
    "        tmp_tp.append(featurize_data(data, ntrain, 'temporal_corr'))\n",
    "        tmp_fq.append(np.mean(featurize_data(data, ntrain, 'freq_spatial'),axis=0))\n",
    "    meg_tp.append(tmp_tp)\n",
    "    meg_fq.append(tmp_fq)\n",
    "    print(i)\n",
    "meg_tp=np.array(meg_tp)\n",
    "meg_fq=np.array(meg_fq)\n",
    "meg_tp = np.expand_dims(meg_tp,0)\n",
    "meg_fq = np.expand_dims(meg_fq,0)\n",
    "\n",
    "\n",
    "eeg_tp = []\n",
    "eeg_fq = []\n",
    "\n",
    "for i in range(len(EEG)):\n",
    "    data = EEG[i].swapaxes(0,2).swapaxes(0,1)\n",
    "    tmp_tp = []\n",
    "    tmp_fq = []\n",
    "    for j in range(n_train_rep):\n",
    "        tmp_tp.append(featurize_data(data, ntrain, 'temporal_corr'))\n",
    "        tmp_fq.append(np.mean(featurize_data(data, ntrain, 'freq_spatial'),axis=0))\n",
    "    eeg_tp.append(tmp_tp)\n",
    "    eeg_fq.append(tmp_fq)\n",
    "    print(i)\n",
    "eeg_tp=np.array(eeg_tp)\n",
    "eeg_fq=np.array(eeg_fq)   \n",
    "eeg_tp = np.expand_dims(eeg_tp,0)\n",
    "eeg_fq = np.expand_dims(eeg_fq,0)\n",
    "\n",
    "sio.savemat(savename,mdict={'eeg_tp':eeg_tp,'eeg_fq':eeg_fq,'meg_tp':meg_tp,'meg_fq':meg_fqDD})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
